{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpxYLWf0zQc4JGWhoMQmWr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ataraxia1001/Login_project/blob/main/Data_analysis_visualization/busstop_total_population_monthly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⭐️ 버스 정류소 월별 승하차 인원 합계 및 정류소 위치 정보\n",
        "- 목표: 월평균 유동인구가 많은 버스정류장의 위치 데이터\n",
        "  - 1단계 : 데이터 전처리\n",
        "    - 필요없는 컬럼 삭제\n",
        "    - 병합을 위해 컬럼 이름 통일 및 데이터 타입 일치시키기\n",
        "    - 해당 자료는 시간대별 승하차 인구를 모두 포함함\n",
        "      - 시간대별 유동인 수가 필요한 것이 아니라 월평균 총유동인구 수가 필요하므로 정류장별 월평균유동인구 값을 구하기(승차, 하차 구분)\n",
        "  - 2단계 : 정류소별 월, 시간대별 승하차 인원 수를 포함하는 데이터프레임과 버스 정류장의 위치 좌표를 가진 데이터프레임 병합"
      ],
      "metadata": {
        "id": "bGFbLkTUEKWQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ 데이터 전처리"
      ],
      "metadata": {
        "id": "cxIRy6gYEhO0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgbnezXdKZey",
        "outputId": "93f274a6-81a6-45c5-9efc-ebc017051549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install haversine\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "qbiOUV7cjnJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from haversine import haversine"
      ],
      "metadata": {
        "id": "zE4Hf6o2KxS2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('/content/drive/MyDrive/project1_login/data/bus_station_boarding/2022년_버스노선별_정류장별_시간대별_승하차_인원_정보(01월).csv', encoding='cp949')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/project1_login/data/bus_station_boarding/2022년_버스노선별_정류장별_시간대별_승하차_인원_정보(02월).csv', encoding='cp949')\n",
        "df3 = pd.read_csv('/content/drive/MyDrive/project1_login/data/bus_station_boarding/2022년_버스노선별_정류장별_시간대별_승하차_인원_정보(03월).csv', encoding='cp949')\n",
        "df4 = pd.read_csv('/content/drive/MyDrive/project1_login/data/bus_station_boarding/2022년_버스노선별_정류장별_시간대별_승하차_인원_정보(04월).csv', encoding='cp949')\n",
        "df5 = pd.read_csv('/content/drive/MyDrive/project1_login/data/bus_station_boarding/2022년_버스노선별_정류장별_시간대별_승하차_인원_정보(05월).csv', encoding='cp949')\n",
        "df6 = pd.read_csv('/content/drive/MyDrive/project1_login/data/bus_station_boarding/2022년_버스노선별_정류장별_시간대별_승하차_인원_정보(06월).csv', encoding='cp949')\n",
        "df7 = pd.read_csv('/content/drive/MyDrive/project1_login/data/bus_station_boarding/2022년_버스노선별_정류장별_시간대별_승하차_인원_정보(07월).csv', encoding='cp949')\n",
        "df8 = pd.read_csv('/content/drive/MyDrive/project1_login/data/bus_station_boarding/2022년_버스노선별_정류장별_시간대별_승하차_인원_정보(08월).csv', encoding='cp949')\n",
        "df9 = pd.read_csv('/content/drive/MyDrive/project1_login/data/bus_station_boarding/2022년_버스노선별_정류장별_시간대별_승하차_인원_정보(09월).csv', encoding='cp949')\n",
        "df10 = pd.read_csv('/content/drive/MyDrive/project1_login/data/bus_station_boarding/2022년_버스노선별_정류장별_시간대별_승하차_인원_정보(10월).csv', encoding='cp949')\n",
        "df11 = pd.read_csv('/content/drive/MyDrive/project1_login/data/bus_station_boarding/2022년_버스노선별_정류장별_시간대별_승하차_인원_정보(11월).csv', encoding='cp949')\n",
        "df12 = pd.read_csv('/content/drive/MyDrive/project1_login/data/bus_station_boarding/2022년_버스노선별_정류장별_시간대별_승하차_인원_정보(12월).csv', encoding='cp949')\n",
        "\n",
        "stop_loc = pd.read_excel('/content/drive/MyDrive/project1_login/data/bus_station_boarding/bus_stop_location_seoul.xlsx')"
      ],
      "metadata": {
        "id": "2BtAD97lmbvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "id": "y3zdWOsWpJzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "Q8tTcLjRpmQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 컬렴명 비교\n",
        "# 3,4,5,6월의 사용년월 컬럼이름이 다름 - 일치 시켜줄 것\n",
        "# 8월부터 추가된 필요없는 추가 컬럼 제거 - '교통수단타입코드', '교통수단타입명', '등록일자'\n",
        "print(df1.columns)\n",
        "print(df2.columns)\n",
        "print(df3.columns)\n",
        "print(df4.columns)\n",
        "print(df5.columns)\n",
        "print(df6.columns)\n",
        "print(df7.columns)\n",
        "print(df8.columns)\n",
        "print(df9.columns)\n",
        "print(df10.columns)\n",
        "print(df11.columns)"
      ],
      "metadata": {
        "id": "fI9HoCZ9Fbw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_loc.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oyanojxp2h2",
        "outputId": "28374151-5b0e-44ea-d7ee-7dcf146889cc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11226 entries, 0 to 11225\n",
            "Data columns (total 5 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   NODE_ID  11226 non-null  int64  \n",
            " 1   ARS-ID   11226 non-null  int64  \n",
            " 2   정류소명     11226 non-null  object \n",
            " 3   X좌표      11226 non-null  float64\n",
            " 4   Y좌표      11226 non-null  float64\n",
            "dtypes: float64(2), int64(2), object(1)\n",
            "memory usage: 438.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head(2)"
      ],
      "metadata": {
        "id": "HCLbvCYhr3yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df1['표준버스정류장ID'].unique())"
      ],
      "metadata": {
        "id": "e5E1SgINvhTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['버스정류장ARS번호'].value_counts()"
      ],
      "metadata": {
        "id": "zlz7RSV-vNDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리 함수\n",
        "def data_cleaning(df):\n",
        "  # 필요없는 컬럼 드롭\n",
        "  df.drop(labels=['노선명', '등록일자'], axis=1, inplace=True)\n",
        "  \n",
        "  if '교통수단타입코드' in df.columns:\n",
        "    df.drop('교통수단타입코드', axis=1, inplace=True)\n",
        "  \n",
        "  if '교통수단타입명' in df.columns:\n",
        "    df.drop('교통수단타입명', axis=1, inplace=True)\n",
        "    \n",
        "  # 컬럼명 통합\n",
        "  if '?\"사용년월\"' in df.columns:\n",
        "    df = df.rename(columns={'?\"사용년월\"':'사용년월', '표준버스정류장ID': 'node_id', '버스정류장ARS번호': 'ars_id'})\n",
        "  else:\n",
        "    df = df.rename(columns={'표준버스정류장ID': 'node_id', '버스정류장ARS번호': 'ars_id'})\n",
        "  \n",
        "  # 사용년월 결측값 채우기(ffill)\n",
        "  df['사용년월'] = df['사용년월'].fillna(method='ffill')\n",
        "  \n",
        "  # 변수 타입 변경\n",
        "  df['사용년월'] = df['사용년월'].astype('str')\n",
        "  # ARS_ID의 값중 '~'가 포함된 정류장은 실제 승하차가 이뤄지지 않는 위치 추적용 가상 정류장이므로 드롭 후 int로 형변환\n",
        "  drop_index = (df[df['ars_id'] == '~']).index\n",
        "  df = df.drop(drop_index, axis=0)\n",
        "  df['ars_id'] = df['ars_id'].astype('int')\n",
        "\n",
        "  # 승하차 총합계 컬럼 추가\n",
        "  df['승차총합계'] = df.iloc[:, 5::2].apply(np.sum, axis=1)\n",
        "  df['하차총합계'] = df.iloc[:, 6::2].apply(np.sum, axis=1)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "Xsu7kO_0sEzS"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = data_cleaning(df1)\n",
        "df2 = data_cleaning(df2)\n",
        "df3 = data_cleaning(df3)\n",
        "df4 = data_cleaning(df4)\n",
        "df5 = data_cleaning(df5)\n",
        "df6 = data_cleaning(df6)\n",
        "df7 = data_cleaning(df7)\n",
        "df8 = data_cleaning(df8)\n",
        "df9 = data_cleaning(df9)\n",
        "df10 = data_cleaning(df10)\n",
        "df11 = data_cleaning(df11)\n",
        "df12 = data_cleaning(df12)"
      ],
      "metadata": {
        "id": "sH2UEM_hBQFN"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df7.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq9bSiIrI18s",
        "outputId": "d2c940fc-35a2-4d37-90bc-c6bfe023ff09"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['사용년월', '노선번호', 'node_id', 'ars_id', '역명', '00시승차총승객수', '00시하차총승객수',\n",
              "       '1시승차총승객수', '1시하차총승객수', '2시승차총승객수', '2시하차총승객수', '3시승차총승객수', '3시하차총승객수',\n",
              "       '4시승차총승객수', '4시하차총승객수', '5시승차총승객수', '5시하차총승객수', '6시승차총승객수', '6시하차총승객수',\n",
              "       '7시승차총승객수', '7시하차총승객수', '8시승차총승객수', '8시하차총승객수', '9시승차총승객수', '9시하차총승객수',\n",
              "       '10시승차총승객수', '10시하차총승객수', '11시승차총승객수', '11시하차총승객수', '12시승차총승객수',\n",
              "       '12시하차총승객수', '13시승차총승객수', '13시하차총승객수', '14시승차총승객수', '14시하차총승객수',\n",
              "       '15시승차총승객수', '15시하차총승객수', '16시승차총승객수', '16시하차총승객수', '17시승차총승객수',\n",
              "       '17시하차총승객수', '18시승차총승객수', '18시하차총승객수', '19시승차총승객수', '19시하차총승객수',\n",
              "       '20시승차총승객수', '20시하차총승객수', '21시승차총승객수', '21시하차총승객수', '22시승차총승객수',\n",
              "       '22시하차총승객수', '23시승차총승객수', '23시하차총승객수', '승차총합계', '하차총합계'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df7.info()"
      ],
      "metadata": {
        "id": "R3V5w4bIITz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 월평균 유동인구총합 구하기"
      ],
      "metadata": {
        "id": "WHR4dFXZNZQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_list = [df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12]\n",
        "# df = pd.merge(df_list, )ㄴㅇㄹㅁㄴㅁㄴㅇㄹㅁㄴㅇㄹㅁㄴㅇㄹㅁㄴㅇㄹㅁㄴㅇㄹㄴㅁㅇㄹㅁㄴㅇㄹㅁㄴㅇㄹㅁㄴㅇㄹㅇㄴㅁㄹㅁㄴㅇㄹㄴㅁㅇㄹㅁㄴㅇㄹㅁㄴㅇㄹㄴㅇㅁㄹㅁㄴㅇㄹㅁㄴㅇㄹㅁㄴㅇㄹ"
      ],
      "metadata": {
        "id": "hjVmsx9SM66A"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AIsaXNybXRDx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}